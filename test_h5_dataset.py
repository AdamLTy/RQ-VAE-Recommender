#!/usr/bin/env python3
"""
æµ‹è¯•è„šæœ¬ï¼šéªŒè¯H5SequenceDatasetåŠŸèƒ½çš„æ­£ç¡®æ€§

è¯¥è„šæœ¬æµ‹è¯•ï¼š
1. æ•°æ®é›†åˆ›å»ºï¼ˆè®­ç»ƒ/éªŒè¯æ¨¡å¼ï¼‰
2. åºåˆ—åˆ†å‰²é€»è¾‘ï¼ˆå‰n-1é¡¹ä½œä¸ºè¾“å…¥ï¼Œæœ€å1é¡¹ä½œä¸ºç›®æ ‡ï¼‰
3. æ•°æ®åŠ è½½å™¨åˆ›å»ºå’Œæ‰¹å¤„ç†
4. test_ratioå‚æ•°ä¸å†å½±å“åˆ†å‰²
"""

import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from data.h5_dataset import H5SequenceDataset, create_h5_sequence_dataloader


def test_h5_dataset_functionality():
    """æµ‹è¯•H5SequenceDatasetçš„ä¸»è¦åŠŸèƒ½"""
    
    # ä½¿ç”¨å‡çš„æ•°æ®é›†è·¯å¾„è¿›è¡Œæµ‹è¯•
    h5_sequence_data_path = "h5/sequence.h5"  # å‡è®¾çš„è·¯å¾„
    max_seq_len = 200
    batch_size = 32
    
    print("=== æµ‹è¯•H5SequenceDatasetåŠŸèƒ½ ===")
    print(f"æ•°æ®é›†è·¯å¾„: {h5_sequence_data_path}")
    print(f"æœ€å¤§åºåˆ—é•¿åº¦: {max_seq_len}")
    print(f"æ‰¹æ¬¡å¤§å°: {batch_size}")
    
    try:
        print("\n1. æµ‹è¯•è®­ç»ƒæ•°æ®é›†åˆ›å»º...")
        train_dataset = H5SequenceDataset(
            sequence_data_path=h5_sequence_data_path,
            is_train=True,
            max_seq_len=max_seq_len,
            subsample=False
        )
        print(f"âœ… è®­ç»ƒæ•°æ®é›†åˆ›å»ºæˆåŠŸï¼Œé•¿åº¦: {len(train_dataset)}")
        
        print("\n2. æµ‹è¯•éªŒè¯æ•°æ®é›†åˆ›å»º...")
        eval_dataset = H5SequenceDataset(
            sequence_data_path=h5_sequence_data_path,
            is_train=False,
            max_seq_len=max_seq_len,
            subsample=False
        )
        print(f"âœ… éªŒè¯æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼Œé•¿åº¦: {len(eval_dataset)}")
        
        # éªŒè¯è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†é•¿åº¦ç›¸åŒï¼ˆå› ä¸ºéƒ½ä½¿ç”¨æ‰€æœ‰åºåˆ—ï¼‰
        print(f"\n3. éªŒè¯æ•°æ®é›†é•¿åº¦ä¸€è‡´æ€§...")
        assert len(train_dataset) == len(eval_dataset), \
            f"è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†é•¿åº¦åº”è¯¥ç›¸åŒ: train={len(train_dataset)}, eval={len(eval_dataset)}"
        print("âœ… è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†é•¿åº¦ä¸€è‡´")
        
        print("\n4. æµ‹è¯•å•ä¸ªæ ·æœ¬è·å–...")
        sample = train_dataset[0]
        print(f"ç”¨æˆ·ID: {sample.user_ids}")
        print(f"åºåˆ—ID shape: {sample.ids.shape}")
        print(f"æœªæ¥ID shape: {sample.ids_fut.shape}")
        print(f"åºåˆ—ç‰¹å¾ shape: {sample.x.shape}")
        print(f"æœªæ¥ç‰¹å¾ shape: {sample.x_fut.shape}")
        print(f"åºåˆ—mask shape: {sample.seq_mask.shape}")
        
        # æ£€æŸ¥åºåˆ—åˆ†å‰²é€»è¾‘
        valid_positions = sample.seq_mask.sum().item()
        print(f"æœ‰æ•ˆåºåˆ—ä½ç½®æ•°: {valid_positions}")
        print("âœ… æ ·æœ¬è·å–æˆåŠŸ")
        
        print("\n5. æµ‹è¯•è®­ç»ƒæ•°æ®åŠ è½½å™¨åˆ›å»º...")
        train_dataloader = create_h5_sequence_dataloader(
            sequence_data_path=h5_sequence_data_path,
            batch_size=batch_size,
            is_train=True,
            max_seq_len=max_seq_len,
            subsample=False,
            shuffle=True
        )
        print(f"âœ… è®­ç»ƒæ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸï¼Œæ‰¹æ¬¡æ•°: {len(train_dataloader)}")
        
        print("\n6. æµ‹è¯•éªŒè¯æ•°æ®åŠ è½½å™¨åˆ›å»º...")
        eval_dataloader = create_h5_sequence_dataloader(
            sequence_data_path=h5_sequence_data_path,
            batch_size=batch_size,
            is_train=False,
            max_seq_len=max_seq_len,
            subsample=False,
            shuffle=False
        )
        print(f"âœ… éªŒè¯æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸï¼Œæ‰¹æ¬¡æ•°: {len(eval_dataloader)}")
        
        print("\n7. æµ‹è¯•æ‰¹æ¬¡æ•°æ®è·å–...")
        for batch_idx, batch in enumerate(train_dataloader):
            print(f"æ‰¹æ¬¡ {batch_idx}:")
            print(f"  user_ids shape: {batch.user_ids.shape}")
            print(f"  ids shape: {batch.ids.shape}")
            print(f"  ids_fut shape: {batch.ids_fut.shape}")
            print(f"  x shape: {batch.x.shape}")
            print(f"  x_fut shape: {batch.x_fut.shape}")
            print(f"  seq_mask shape: {batch.seq_mask.shape}")
            
            # éªŒè¯æ‰¹æ¬¡ç»´åº¦
            actual_batch_size = batch.user_ids.shape[0]
            assert batch.ids.shape[0] == actual_batch_size
            assert batch.ids_fut.shape[0] == actual_batch_size
            assert batch.x.shape[0] == actual_batch_size
            assert batch.x_fut.shape[0] == actual_batch_size
            assert batch.seq_mask.shape[0] == actual_batch_size
            
            print(f"  å®é™…æ‰¹æ¬¡å¤§å°: {actual_batch_size}")
            break  # åªæµ‹è¯•ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
        
        print("âœ… æ‰¹æ¬¡æ•°æ®è·å–æˆåŠŸ")
        
        print("\n8. æµ‹è¯•test_ratioå‚æ•°è¢«å¿½ç•¥...")
        # ä½¿ç”¨ä¸åŒçš„test_ratioå€¼åˆ›å»ºæ•°æ®é›†ï¼Œé•¿åº¦åº”è¯¥ç›¸åŒ
        dataset_ratio_01 = H5SequenceDataset(
            sequence_data_path=h5_sequence_data_path,
            is_train=True,
            max_seq_len=max_seq_len,
            test_ratio=0.1,
            subsample=False
        )
        
        dataset_ratio_09 = H5SequenceDataset(
            sequence_data_path=h5_sequence_data_path,
            is_train=True,
            max_seq_len=max_seq_len,
            test_ratio=0.9,
            subsample=False
        )
        
        assert len(dataset_ratio_01) == len(dataset_ratio_09), \
            f"ä¸åŒtest_ratioçš„æ•°æ®é›†é•¿åº¦åº”è¯¥ç›¸åŒ: {len(dataset_ratio_01)} vs {len(dataset_ratio_09)}"
        print(f"âœ… test_ratioå‚æ•°è¢«æ­£ç¡®å¿½ç•¥ï¼Œæ•°æ®é›†é•¿åº¦å‡ä¸º: {len(dataset_ratio_01)}")
        
        print("\n9. æµ‹è¯•åºåˆ—åˆ†å‰²é€»è¾‘...")
        # è·å–å‡ ä¸ªæ ·æœ¬æ¥éªŒè¯åˆ†å‰²é€»è¾‘
        for i in range(min(3, len(train_dataset))):
            sample = train_dataset[i]
            valid_mask = sample.seq_mask.numpy()
            valid_ids = sample.ids.numpy()[valid_mask]
            target_id = sample.ids_fut.numpy()[0]
            
            print(f"åºåˆ— {i}:")
            print(f"  è¾“å…¥åºåˆ—é•¿åº¦: {len(valid_ids)}")
            print(f"  è¾“å…¥åºåˆ—: {valid_ids[:5]}..." if len(valid_ids) > 5 else f"  è¾“å…¥åºåˆ—: {valid_ids}")
            print(f"  ç›®æ ‡ç‰©å“: {target_id}")
            
            # éªŒè¯ç›®æ ‡ä¸æ˜¯-1ï¼ˆé™¤éæ˜¯å•ç‰©å“åºåˆ—ï¼‰
            if len(valid_ids) > 0:
                assert target_id >= -1, f"ç›®æ ‡ç‰©å“IDåº”è¯¥ >= -1: {target_id}"
        
        print("âœ… åºåˆ—åˆ†å‰²é€»è¾‘éªŒè¯é€šè¿‡")
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        
    except FileNotFoundError as e:
        print(f"âŒ æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        print("è¯·ç¡®ä¿H5æ•°æ®æ–‡ä»¶å­˜åœ¨æˆ–æ›´æ–°æ–‡ä»¶è·¯å¾„")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def test_different_configurations():
    """æµ‹è¯•ä¸åŒé…ç½®å‚æ•°"""
    
    h5_sequence_data_path = "h5/sequence.h5"
    
    print("\n=== æµ‹è¯•ä¸åŒé…ç½®å‚æ•° ===")
    
    configs = [
        {"max_seq_len": 50, "subsample": False, "is_train": True},
        {"max_seq_len": 100, "subsample": True, "is_train": True},
        {"max_seq_len": 200, "subsample": False, "is_train": False},
    ]
    
    try:
        for i, config in enumerate(configs):
            print(f"\né…ç½® {i+1}: {config}")
            
            dataset = H5SequenceDataset(
                sequence_data_path=h5_sequence_data_path,
                **config
            )
            
            print(f"  æ•°æ®é›†é•¿åº¦: {len(dataset)}")
            
            # æµ‹è¯•ç¬¬ä¸€ä¸ªæ ·æœ¬
            if len(dataset) > 0:
                sample = dataset[0]
                valid_positions = sample.seq_mask.sum().item()
                print(f"  ç¬¬ä¸€ä¸ªæ ·æœ¬æœ‰æ•ˆä½ç½®æ•°: {valid_positions}")
                print(f"  æœ€å¤§åºåˆ—é•¿åº¦é™åˆ¶: {config['max_seq_len']}")
                
                assert valid_positions <= config['max_seq_len'], \
                    f"æœ‰æ•ˆä½ç½®æ•°ä¸åº”è¶…è¿‡æœ€å¤§åºåˆ—é•¿åº¦: {valid_positions} > {config['max_seq_len']}"
        
        print("âœ… ä¸åŒé…ç½®å‚æ•°æµ‹è¯•é€šè¿‡")
        
    except Exception as e:
        print(f"âŒ é…ç½®æµ‹è¯•å¤±è´¥: {e}")


if __name__ == "__main__":
    print("å¼€å§‹æµ‹è¯•H5SequenceDatasetåŠŸèƒ½\n")
    
    # ä¸»è¦åŠŸèƒ½æµ‹è¯•
    test_h5_dataset_functionality()
    
    # ä¸åŒé…ç½®æµ‹è¯•
    test_different_configurations()
    
    print("\næµ‹è¯•å®Œæˆï¼")