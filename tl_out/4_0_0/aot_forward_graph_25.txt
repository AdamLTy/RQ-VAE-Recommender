class GraphModule(torch.nn.Module):
    def forward(self, primals_1: "f32[s0, 128][128, 1]cuda:0", primals_2: "i64[257][1]cuda:0", primals_3: "f32[s3, 0][1, 1]cuda:0", primals_4: "f32[s4, 0][1, 1]cuda:0", primals_5: "Sym(s1)", primals_6: "f32[128][1]cuda:0"):
         # File: /home/ec2-user/code/RQ-VAE-Recommender/modules/normalize.py:28 in _norm, code: return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)
        pow_1: "f32[s0, 128][128, 1]cuda:0" = torch.ops.aten.pow.Tensor_Scalar(primals_1, 2)
        mean: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.mean.dim(pow_1, [1], True);  pow_1 = None
        add: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(mean, 1e-06);  mean = None
        rsqrt: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add);  add = None
        mul: "f32[s0, 128][128, 1]cuda:0" = torch.ops.aten.mul.Tensor(primals_1, rsqrt)
        
         # File: /home/ec2-user/code/RQ-VAE-Recommender/modules/normalize.py:32 in forward, code: return output * self.weight
        mul_1: "f32[s0, 128][128, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul, primals_6);  mul = primals_6 = None
        return (mul_1, primals_2, primals_3, primals_4, primals_1, rsqrt)
        