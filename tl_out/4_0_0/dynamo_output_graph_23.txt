class GraphModule(torch.nn.Module):
    def forward(self, L_x_: "f32[256, s1, 128][128*s1, 128, 1]cuda:0", s1: "Sym(s1)", L_self_parameters_weight_: "f32[128][1]cuda:0"):
        l_x_ = L_x_
        l_self_parameters_weight_ = L_self_parameters_weight_
        
         # File: /home/ec2-user/code/RQ-VAE-Recommender/modules/normalize.py:31 in forward, code: output = self._norm(x.float()).type_as(x)
        float_1: "f32[256, s1, 128][128*s1, 128, 1]cuda:0" = l_x_.float()
        
         # File: /home/ec2-user/code/RQ-VAE-Recommender/modules/normalize.py:28 in _norm, code: return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)
        pow_1: "f32[256, s1, 128][128*s1, 128, 1]cuda:0" = float_1.pow(2)
        mean: "f32[256, s1, 1][s1, 1, 1]cuda:0" = pow_1.mean(-1, keepdim = True);  pow_1 = None
        add: "f32[256, s1, 1][s1, 1, 1]cuda:0" = mean + 1e-06;  mean = None
        rsqrt: "f32[256, s1, 1][s1, 1, 1]cuda:0" = torch.rsqrt(add);  add = None
        mul: "f32[256, s1, 128][128*s1, 128, 1]cuda:0" = float_1 * rsqrt;  float_1 = rsqrt = None
        
         # File: /home/ec2-user/code/RQ-VAE-Recommender/modules/normalize.py:31 in forward, code: output = self._norm(x.float()).type_as(x)
        output: "f32[256, s1, 128][128*s1, 128, 1]cuda:0" = mul.type_as(l_x_);  mul = l_x_ = None
        
         # File: /home/ec2-user/code/RQ-VAE-Recommender/modules/normalize.py:32 in forward, code: return output * self.weight
        mul_1: "f32[256, s1, 128][128*s1, 128, 1]cuda:0" = output * l_self_parameters_weight_;  output = l_self_parameters_weight_ = None
        return (mul_1,)
        