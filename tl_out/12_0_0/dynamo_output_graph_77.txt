class GraphModule(torch.nn.Module):
    def forward(self, L_stack0_: "f32[256, s0, 384][384*s0, 384, 1]cuda:0", s0: "Sym(s0)", L_self_modules_out_proj_parameters_weight_: "f32[256, 384][384, 1]cuda:0", L_batch_2_: "i64[256, 4][4, 1]cuda:0"):
        l_stack0_ = L_stack0_
        l_self_modules_out_proj_parameters_weight_ = L_self_modules_out_proj_parameters_weight_
        l_batch_2_ = L_batch_2_
        
         # File: /home/ec2-user/code/RQ-VAE-Recommender/modules/model.py:429 in torch_dynamo_resume_in_forward_at_426, code: predict_out = self.out_proj(trnsf_out)
        predict_out: "f32[256, s0, 256][256*s0, 256, 1]cuda:0" = torch._C._nn.linear(l_stack0_, l_self_modules_out_proj_parameters_weight_, None);  l_stack0_ = l_self_modules_out_proj_parameters_weight_ = None
        
         # File: /home/ec2-user/code/RQ-VAE-Recommender/modules/utils.py:67 in jagged_to_flattened_tensor, code: return x.values()
        values: "f32[s1, 256][256, 1]cuda:0" = predict_out.values();  predict_out = None
        
         # File: /home/ec2-user/code/RQ-VAE-Recommender/modules/model.py:431 in torch_dynamo_resume_in_forward_at_426, code: logits = rearrange(jagged_to_flattened_tensor(predict_out), "(b n) d -> b n d", b=B)[:,:-1,:].flatten(end_dim=1)
        rearrange: "f32[256, (s1//256), 256][256*((s1//256)), 256, 1]cuda:0" = einops_einops_rearrange(values, '(b n) d -> b n d', b = 256);  values = None
        getitem: "f32[256, (s1//256) - 1, 256][256*((s1//256)), 256, 1]cuda:0" = rearrange[(slice(None, None, None), slice(None, -1, None), slice(None, None, None))];  rearrange = None
        logits: "f32[256*((s1//256)) - 256, 256][256, 1]cuda:0" = getitem.flatten(end_dim = 1);  getitem = None
        
         # File: /home/ec2-user/code/RQ-VAE-Recommender/modules/model.py:432 in torch_dynamo_resume_in_forward_at_426, code: target = batch.sem_ids_fut.flatten(end_dim=1)
        target: "i64[1024][1]cuda:0" = l_batch_2_.flatten(end_dim = 1);  l_batch_2_ = None
        
         # File: /home/ec2-user/code/RQ-VAE-Recommender/modules/model.py:433 in torch_dynamo_resume_in_forward_at_426, code: loss = rearrange(F.cross_entropy(logits, target, reduction="none", ignore_index=-1), "(b n) -> b n", b=B).sum(axis=1).mean()
        cross_entropy: "f32[1024][1]cuda:0" = torch.nn.functional.cross_entropy(logits, target, reduction = 'none', ignore_index = -1);  target = None
        rearrange_1: "f32[256, 4][4, 1]cuda:0" = einops_einops_rearrange(cross_entropy, '(b n) -> b n', b = 256);  cross_entropy = None
        sum_1: "f32[256][1]cuda:0" = rearrange_1.sum(axis = 1);  rearrange_1 = None
        loss: "f32[][]cuda:0" = sum_1.mean();  sum_1 = None
        return (loss, logits)
        