class GraphModule(torch.nn.Module):
    def forward(self, primals_1: "f32[s1, 384][384, 1]cuda:0", primals_2: "i64[257][1]cuda:0", primals_3: "f32[s3, 0][1, 1]cuda:0", primals_4: "f32[s4, 0][1, 1]cuda:0", primals_5: "Sym(s0)", primals_6: "f32[1024, 384][384, 1]cuda:0", primals_7: "f32[384, 1024][1024, 1]cuda:0"):
         # File: /home/ec2-user/code/RQ-VAE-Recommender/modules/encoder.py:36 in forward, code: return self.mlp(x)
        permute: "f32[384, 1024][1, 384]cuda:0" = torch.ops.aten.permute.default(primals_6, [1, 0])
        mm: "f32[s1, 1024][1024, 1]cuda:0" = torch.ops.aten.mm.default(primals_1, permute);  permute = None
        sigmoid: "f32[s1, 1024][1024, 1]cuda:0" = torch.ops.aten.sigmoid.default(mm)
        mul: "f32[s1, 1024][1024, 1]cuda:0" = torch.ops.aten.mul.Tensor(mm, sigmoid);  sigmoid = None
        sym_size_int: "Sym(s1)" = torch.ops.aten.sym_size.int(primals_1, 0)
        
        # No stacktrace found for following nodes
        inductor_seeds_default: "i64[1][1]cuda:0" = torch.ops.prims.inductor_seeds.default(1, device(type='cuda', index=0))
        inductor_lookup_seed_default: "i64[][]cuda:0" = torch.ops.prims.inductor_lookup_seed.default(inductor_seeds_default, 0);  inductor_seeds_default = None
        inductor_random_default: "f32[s1, 1024][1024, 1]cuda:0" = torch.ops.prims.inductor_random.default([sym_size_int, 1024], inductor_lookup_seed_default, 'rand');  inductor_lookup_seed_default = None
        
         # File: /home/ec2-user/code/RQ-VAE-Recommender/modules/encoder.py:36 in forward, code: return self.mlp(x)
        gt: "b8[s1, 1024][1024, 1]cuda:0" = torch.ops.aten.gt.Scalar(inductor_random_default, 0.3);  inductor_random_default = None
        mul_1: "f32[s1, 1024][1024, 1]cuda:0" = torch.ops.aten.mul.Tensor(gt, mul);  mul = None
        mul_2: "f32[s1, 1024][1024, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1, 1.4285714285714286);  mul_1 = None
        permute_1: "f32[1024, 384][1, 1024]cuda:0" = torch.ops.aten.permute.default(primals_7, [1, 0])
        mm_1: "f32[s1, 384][384, 1]cuda:0" = torch.ops.aten.mm.default(mul_2, permute_1);  permute_1 = None
        return (mm_1, primals_2, primals_3, primals_4, primals_1, primals_6, primals_7, mm, gt, mul_2, sym_size_int)
        